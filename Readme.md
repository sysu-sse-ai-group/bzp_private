# 汇报进度

## 项目概况

 对大模型高效推理做研究，对文本生成，代码生成等方面嵌入RAG（检索增强生成）等技术的微调，再看能否将nlp领域的思维链引入

## 进度更新

### 本周工作完成情况

- 阅读论文：KnowGPT: Black-Box Knowledge Injection for Large Language     Models
  了解了KnowGPT的黑盒知识注入框架

- 阅读论文：Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks 
   了解到RAG是参数化知识＋非参数化知识的结合，所以即是检索不到有用的相关文档，也可以单凭参数化的知识(BART)，根据模型学到的知识回答出正确的答案；
   RAG的灵活性很高。要改变预训练的语言模型所知道的内容，需要用新的文档对整个模型进行再训练。通过 RAG，我们可以通过交换知识检索所用的文档来控制它所知道的内容。

- 寻找到初步的数据（包括论文，算法代码已经试验结果），并且进行了embedding，还进行了余弦相似度对比

## 问题

- 问题1：用哪些模型，只用一些nlp模型可以吗？（chatgpt，Llama，BERT，WenBERT）
- 问题2：在embedding部分要不要分析

## 下一步计划

- 寻找更多大语言模型的代表
- 寻找更有说服力的训练例子
- 了解评估体系

## 资源需求

- 一些大模型体量太大，训练需要较大的计算资源，希望得到学院的服务器利用权限

- 2024/2/8

- 制作了rag相关的ppt学习文件

2024/2/20

- 探索THUDM的chatglm模型

# 时间表计划：使用RAG技术大型语言模型幻觉问题

## 3月12日 - 3月15日

  **周目标：** 研究方向和目标。
- 撰写毕业论文中期报告。
- 寻找三种有象征性的RAG结构，寻找思维链等其余解决大模型幻觉的方法。
- 搭建langchain环境，寻找医学，文学，生物领域的数据集，进行初步实验。

## 3月16日 - 3月22日

  **周目标：** 完成并且完善实验
- 找出合适的评估体系
- 进行对不同数据分类，将RAG与其他解决幻觉的方式进行评估对比。


## 3月23日 - 3月29日

  **周目标：** 实验和结果分析。
- 开始撰写论文，
- 继续训练和评估对比RAG，与其他模型店数据。

## 3月30日 - 4月5日

- **周目标：** 撰写论文＋探索部分RAG的创新特性
- 其中论文计划包括以下内容：
（1）abstract：简介
（2）introduction：表明大语言模型幻觉现状和产生的原因，RAG和传统方法比较的优势
（3）related work：写了主要的工作
（4）Generation-Augmented Retrieval：几种代表性的RAG的机制原理
（5）traditional method：几种传统的解决幻觉方法的原理
（6）experiment：实验平台＋数据集＋评估结果
（7）conclusion：总结
（8）future extension：未来应用的展望

## 4月6日 - 4月15日

- **周目标：** 撰写论文，并且完成初稿
- 学有余力，可以开发一个利用RAG模型的问答网站




